# Sample Cost Comparison Report

<!-- SPDX-License-Identifier: Apache-2.0 -->
<!-- Copyright 2025 Scott Friedman and Project Contributors -->

This document provides sample cost comparison reports generated by the NVIDIA Jetson Workload suite. These examples illustrate how to interpret the cost analysis data and use it to make informed infrastructure decisions.

## Basic Cost Comparison

The following report compares execution costs between a Jetson Orin NX and cloud GPU instances for the N-body simulation workload:

![Cost Comparison](../images/sample-cost-comparison.png)

### Interpreting the Results

The cost comparison shows:

- **Absolute Cost**: The Jetson Orin NX ($0.0024) is significantly more cost-effective than all cloud options for this workload, with AWS g4dn.xlarge ($0.0193) being 8.0x more expensive.

- **Cost per Operation**: The Jetson achieves 3.45M operations per dollar, compared to 0.43M for AWS, 0.38M for Azure, and 0.41M for GCP.

- **Break-Even Analysis**: The Jetson hardware cost would be recovered in approximately 612 hours (about 25.5 days) of continuous operation compared to using AWS.

### Cost Comparison Table

| Workload | Device | Jetson Cost | AWS Cost | Azure Cost | GCP Cost | AWS/Jetson Ratio | Azure/Jetson Ratio | GCP/Jetson Ratio |
|----------|--------|-------------|----------|------------|----------|------------------|-------------------|------------------|
| nbody_100k | Jetson Orin NX | $0.0024 | $0.0193 | $0.0215 | $0.0202 | 8.0x | 9.0x | 8.4x |
| weather_1024 | Jetson Orin NX | $0.0038 | $0.0287 | $0.0304 | $0.0296 | 7.6x | 8.0x | 7.8x |
| medical_ct_512 | Jetson Orin NX | $0.0062 | $0.0412 | $0.0438 | $0.0405 | 6.6x | 7.1x | 6.5x |

## Enterprise Computing Comparison

For larger-scale enterprise deployments, the cost comparison includes NVIDIA DGX systems and Slurm clusters:

![Enterprise Comparison](../images/sample-enterprise-comparison.png)

### Interpreting the Results

The enterprise comparison shows:

- **Absolute Cost**: For the weather simulation workload, a Jetson-based Slurm cluster (16 nodes) offers a cost advantage over a DGX A100 system for this specific workload scale.

- **Cost Ratio**: The DGX A100 is approximately 12.3x more expensive than a single Jetson for the medical imaging workload, while the Jetson-based Slurm cluster is only 3.8x more expensive.

- **Break-Even Analysis**: For high-end GPU clusters, the break-even time compared to cloud instances is approximately 8.5 months, while for Jetson-based clusters it's only 2.3 months.

### Cost Ratio Table by System Type

| Workload | Jetson | DGX A100 | DGX H100 | Basic GPU Cluster (16 nodes) | Jetson Cluster (32 nodes) |
|----------|--------|----------|----------|------------------------------|---------------------------|
| nbody_100k | 1.0x | 15.2x | 22.8x | 5.7x | 3.2x |
| weather_1024 | 1.0x | 7.6x | 11.4x | 4.8x | 2.8x |
| medical_ct_512 | 1.0x | 12.3x | 18.5x | 6.2x | 3.8x |

## System Scaling Analysis

The system scaling analysis shows how costs change as you scale up the number of compute nodes:

![System Scaling](../images/sample-system-scaling.png)

### Interpreting the Results

The scaling analysis reveals:

- **Linear Scaling**: For Jetson-based clusters, cost scales almost linearly with the number of nodes, with a slope of approximately $0.12 per node.

- **DGX SuperPOD**: The DGX SuperPOD shows economies of scale, with the cost per node decreasing as the number of nodes increases.

- **Break-Even Point**: For large-scale workloads (e.g., weather_4096), a Jetson cluster with 64 nodes is more cost-effective than a DGX A100 for total execution times up to 180 hours per month.

## Break-Even Analysis Visualization

The break-even analysis shows how many hours of operation are required before local computing becomes more economical than cloud options:

![Break-Even Analysis](../images/sample-break-even.png)

### Interpreting the Results

The break-even visualization shows:

- **AWS Cloud**: For the N-body simulation, Jetson becomes more cost-effective after 612 hours (25.5 days) of operation.

- **Azure Cloud**: Break-even with Azure occurs after 682 hours (28.4 days) for the same workload.

- **GCP Cloud**: Break-even with GCP occurs after 644 hours (26.8 days).

- **DGX Systems**: For a DGX A100, the break-even time is approximately 8,560 hours (about 12 months) due to the high upfront cost.

## Recommendations Based on Workload Patterns

The following table provides recommendations based on different workload patterns:

| Usage Pattern | Hours per Month | Recommended Infrastructure | Rationale |
|---------------|----------------|---------------------------|-----------|
| Occasional | < 80 | Cloud GPU instances | Below break-even threshold of ~600 hours |
| Regular | 80-200 | Jetson Orin NX | Above break-even with cloud, below enterprise threshold |
| Heavy | 200-500 | Jetson Cluster | Better cost efficiency than cloud for sustained workloads |
| Continuous | > 500 | Appropriately sized Slurm cluster | Most cost-effective for 24/7 operation |
| Batch/HPC | Varies | DGX systems | When computational density and time-to-result are critical |

## How to Generate These Reports

To generate similar reports for your own workloads, use the following commands:

```bash
# Basic cost comparison with cloud providers
python benchmark/benchmark_suite.py --nbody --cost-analysis

# Compare with DGX systems and Slurm clusters
python benchmark/benchmark_suite.py --weather --cost-analysis \
  --dgx-system-type dgx_a100 --dgx-quantity 1 \
  --slurm-node-type jetson_cluster --slurm-nodes 16

# System scaling analysis with different cluster sizes
python benchmark/benchmark_suite.py --medical --cost-analysis \
  --slurm-config benchmark/configs/slurm_cluster_scaling.yaml

# Custom configurations for all components
python benchmark/benchmark_suite.py --all --cost-analysis \
  --dgx-config benchmark/configs/dgx_custom.yaml \
  --slurm-config benchmark/configs/slurm_custom.yaml
```

The HTML reports will be generated in the `benchmark/reports` directory by default, with supporting visualizations in the `benchmark/reports/images` subdirectory.

## Conclusion

Cost analysis provides valuable insights for infrastructure planning and decision-making. The NVIDIA Jetson Workload suite offers comprehensive cost modeling tools that account for hardware amortization, power consumption, maintenance costs, and operational expenses.

For infrastructure planning:

1. **For short-term or occasional workloads**: Cloud computing may be more economical.
2. **For regular, predictable workloads**: Jetson devices offer exceptional value.
3. **For enterprise-scale requirements**: Consider DGX systems when computational density and time-to-solution are critical factors.
4. **For balanced performance/cost**: A Jetson-based cluster provides an excellent middle ground.

Use these sample reports as a guide for interpreting your own cost analysis results and making data-driven infrastructure decisions.