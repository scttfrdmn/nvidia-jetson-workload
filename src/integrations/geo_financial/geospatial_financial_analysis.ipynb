{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Geospatial Financial Risk Analysis\n",
    "\n",
    "<!-- SPDX-License-Identifier: Apache-2.0 -->\n",
    "<!-- Copyright 2025 Scott Friedman and Project Contributors -->\n",
    "\n",
    "This notebook demonstrates the integration between the Financial Modeling and Geospatial Analysis workloads to provide a comprehensive geospatial financial risk analysis.\n",
    "\n",
    "## Overview\n",
    "\n",
    "In this notebook, we will:\n",
    "\n",
    "1. Load and prepare geospatial data, including digital elevation models (DEMs)\n",
    "2. Load and prepare financial data, including asset locations and returns\n",
    "3. Create a geospatial risk model based on multiple spatial risk factors\n",
    "4. Analyze portfolio risk using both financial and geospatial factors\n",
    "5. Optimize a portfolio to minimize exposure to geospatial risks\n",
    "6. Visualize the results of the analysis\n",
    "\n",
    "## Applications\n",
    "\n",
    "This type of analysis is useful for various applications:\n",
    "\n",
    "- Insurance companies assessing risk exposure to natural disasters\n",
    "- Real estate investment trusts (REITs) optimizing property portfolios\n",
    "- Infrastructure investors evaluating project locations\n",
    "- Asset managers incorporating climate change risks into investment decisions\n",
    "- Government agencies allocating resources for disaster mitigation\n",
    "\n",
    "Let's start by importing the necessary modules and setting up our environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import base Python libraries\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set plot style\n",
    "plt.style.use('ggplot')\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "# Set up paths\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..', '..', '..'))\n",
    "sys.path.append(project_root)\n",
    "\n",
    "# Import workload modules\n",
    "from src.geospatial.python.geospatial import dem as geospatial_dem\n",
    "from src.geospatial.python.geospatial import point_cloud as geospatial_pc\n",
    "from src.financial_modeling.python.financial_modeling import risk_metrics\n",
    "from src.financial_modeling.python.financial_modeling import portfolio_optimization\n",
    "\n",
    "# Import integration modules\n",
    "from src.integrations.geo_financial.geo_risk import (\n",
    "    SpatialRiskFactor,\n",
    "    GeospatialRiskModel,\n",
    "    GeospatialPortfolio,\n",
    "    create_elevation_risk_factor,\n",
    "    create_slope_risk_factor\n",
    ")\n",
    "from src.integrations.geo_financial.data_connectors import (\n",
    "    AssetLocationDataLoader,\n",
    "    FinancialDataLoader,\n",
    "    GeoRiskDataLoader\n",
    ")\n",
    "from src.integrations.geo_financial.visualization import GeoFinancialVisualizer\n",
    "\n",
    "# Print module versions\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "print(f\"Pandas version: {pd.__version__}\")\n",
    "print(f\"Matplotlib version: {plt.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Device Selection\n",
    "\n",
    "One of the key features of the workloads is the ability to automatically adapt to available GPU hardware. We'll select the device to use for our computations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check available devices\n",
    "try:\n",
    "    # Import pycuda for device checking\n",
    "    import pycuda.driver as cuda\n",
    "    import pycuda.autoinit\n",
    "    \n",
    "    # Get device count\n",
    "    device_count = cuda.Device.count()\n",
    "    print(f\"Found {device_count} CUDA device(s)\")\n",
    "    \n",
    "    # Print device information\n",
    "    for i in range(device_count):\n",
    "        device = cuda.Device(i)\n",
    "        props = device.get_attributes()\n",
    "        compute_capability = f\"{props[cuda.device_attribute.COMPUTE_CAPABILITY_MAJOR]}.{props[cuda.device_attribute.COMPUTE_CAPABILITY_MINOR]}\"\n",
    "        print(f\"Device {i}: {device.name()} (Compute Capability {compute_capability})\")\n",
    "    \n",
    "    # Set device ID to first available GPU\n",
    "    device_id = 0\n",
    "    print(f\"Using device {device_id} for computations\")\n",
    "    \n",
    "except (ImportError, ModuleNotFoundError):\n",
    "    print(\"PyCUDA not available, using CPU for computations\")\n",
    "    device_id = -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Preparation\n",
    "\n",
    "Now we'll download or load sample data for our analysis. We'll need:\n",
    "\n",
    "1. Geospatial data (DEMs, terrain data)\n",
    "2. Asset location data\n",
    "3. Financial time series data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data directory if it doesn't exist\n",
    "data_dir = os.path.join(project_root, 'data', 'geo_financial')\n",
    "os.makedirs(data_dir, exist_ok=True)\n",
    "\n",
    "# Check if we have sample data, otherwise download it\n",
    "sample_dem_path = os.path.join(data_dir, 'sample_dem.tif')\n",
    "sample_assets_path = os.path.join(data_dir, 'sample_assets.csv')\n",
    "sample_returns_path = os.path.join(data_dir, 'sample_returns.csv')\n",
    "\n",
    "# Use sample data if available, otherwise generate synthetic data\n",
    "if not all(os.path.exists(p) for p in [sample_dem_path, sample_assets_path, sample_returns_path]):\n",
    "    print(\"Generating synthetic data...\")\n",
    "    \n",
    "    # Generate synthetic DEM data\n",
    "    dem_size = 500\n",
    "    x = np.linspace(0, 10, dem_size)\n",
    "    y = np.linspace(0, 10, dem_size)\n",
    "    X, Y = np.meshgrid(x, y)\n",
    "    \n",
    "    # Create a synthetic terrain with hills and valleys\n",
    "    Z = 100 + 50 * np.sin(X * 0.5) * np.cos(Y * 0.5) + 20 * np.sin(X * 2) * np.sin(Y * 2)\n",
    "    \n",
    "    # Add a river valley\n",
    "    river = 80 * np.exp(-((X - 5) ** 2) / 0.5)\n",
    "    Z -= river\n",
    "    \n",
    "    # Save DEM data\n",
    "    try:\n",
    "        import matplotlib.pyplot as plt\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        plt.imshow(Z, cmap='terrain')\n",
    "        plt.colorbar(label='Elevation (m)')\n",
    "        plt.title('Synthetic Digital Elevation Model')\n",
    "        plt.savefig(os.path.join(data_dir, 'synthetic_dem.png'))\n",
    "        \n",
    "        # Save DEM as NumPy array\n",
    "        np.save(os.path.join(data_dir, 'synthetic_dem.npy'), Z)\n",
    "        \n",
    "        # Use the NumPy file as our DEM\n",
    "        sample_dem_path = os.path.join(data_dir, 'synthetic_dem.npy')\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving DEM: {e}\")\n",
    "    \n",
    "    # Generate synthetic asset data\n",
    "    num_assets = 20\n",
    "    asset_data = {\n",
    "        'id': [f\"ASSET_{i:02d}\" for i in range(num_assets)],\n",
    "        'name': [f\"Asset {i}\" for i in range(num_assets)],\n",
    "        'value': np.random.uniform(1000, 10000, num_assets).round(2),\n",
    "        'x': np.random.uniform(0, 10, num_assets),\n",
    "        'y': np.random.uniform(0, 10, num_assets),\n",
    "        'sector': np.random.choice(['Real Estate', 'Infrastructure', 'Agriculture', 'Energy', 'Industrial'], num_assets)\n",
    "    }\n",
    "    assets_df = pd.DataFrame(asset_data)\n",
    "    assets_df.to_csv(sample_assets_path, index=False)\n",
    "    \n",
    "    # Generate synthetic returns data\n",
    "    num_days = 252  # One year of trading days\n",
    "    returns_data = []\n",
    "    \n",
    "    for asset_id in asset_data['id']:\n",
    "        # Generate correlated returns with some randomness\n",
    "        asset_returns = np.random.normal(0.0005, 0.01, num_days)  # Mean 0.05% daily return, 1% std dev\n",
    "        \n",
    "        for i, ret in enumerate(asset_returns):\n",
    "            returns_data.append({\n",
    "                'asset_id': asset_id,\n",
    "                'date': pd.Timestamp('2024-01-01') + pd.Timedelta(days=i),\n",
    "                'return': ret\n",
    "            })\n",
    "    \n",
    "    returns_df = pd.DataFrame(returns_data)\n",
    "    returns_df.to_csv(sample_returns_path, index=False)\n",
    "    \n",
    "    print(\"Synthetic data generated successfully.\")\n",
    "else:\n",
    "    print(\"Using existing sample data.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load and Prepare Data\n",
    "\n",
    "Now let's load and prepare the data for our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load DEM data\n",
    "dem_file = sample_dem_path\n",
    "if dem_file.endswith('.npy'):\n",
    "    # Load from NumPy file\n",
    "    dem_data = np.load(dem_file)\n",
    "    # Create a synthetic geo transform\n",
    "    geo_transform = geospatial_dem.GeoTransform([0, 0.02, 0, 10, 0, -0.02])\n",
    "else:\n",
    "    # Load from GeoTIFF file\n",
    "    dem_processor = geospatial_dem.DEMProcessor(dem_file, device_id=device_id)\n",
    "    dem_data = dem_processor.get_elevation_data()\n",
    "    geo_transform = dem_processor.get_geo_transform()\n",
    "\n",
    "# Visualize DEM data\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.imshow(dem_data, cmap='terrain')\n",
    "plt.colorbar(label='Elevation (m)')\n",
    "plt.title('Digital Elevation Model')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "# Load asset location data\n",
    "asset_loader = AssetLocationDataLoader()\n",
    "assets_df = asset_loader.load_asset_csv(\n",
    "    file_path=sample_assets_path,\n",
    "    id_col='id',\n",
    "    name_col='name',\n",
    "    value_col='value',\n",
    "    x_col='x',\n",
    "    y_col='y'\n",
    ")\n",
    "\n",
    "# Display asset data\n",
    "print(f\"Loaded {len(assets_df)} assets:\")\n",
    "assets_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load returns data\n",
    "financial_loader = FinancialDataLoader()\n",
    "returns_dict = financial_loader.load_returns_csv(\n",
    "    file_path=sample_returns_path,\n",
    "    asset_id_col='asset_id',\n",
    "    date_col='date',\n",
    "    return_col='return'\n",
    ")\n",
    "\n",
    "# Attach returns to assets\n",
    "assets_df_with_returns = financial_loader.attach_returns_to_assets(\n",
    "    assets_df=assets_df,\n",
    "    returns_dict=returns_dict,\n",
    "    asset_id_col='id'\n",
    ")\n",
    "\n",
    "# Check that returns were attached correctly\n",
    "print(f\"Returns data attached to {sum(assets_df_with_returns['returns'].apply(len) > 0)} assets\")\n",
    "print(f\"Example returns shape for first asset: {assets_df_with_returns['returns'].iloc[0].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Create Spatial Risk Factors\n",
    "\n",
    "Now we'll create spatial risk factors based on the DEM data. These factors will represent different types of geospatial risk (e.g., flood risk, landslide risk)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create elevation-based risk factor (flood risk)\n",
    "# Lower elevations have higher risk\n",
    "flood_risk = SpatialRiskFactor(\n",
    "    name=\"Flood Risk\",\n",
    "    description=\"Risk based on elevation (lower elevations have higher risk)\",\n",
    "    risk_weight=0.7,\n",
    "    spatial_data=dem_data,\n",
    "    geo_transform=geo_transform,\n",
    "    transform_func=lambda elev: 1.0 - np.clip((elev - np.min(elev)) / (np.max(elev) - np.min(elev)), 0, 1)\n",
    ")\n",
    "\n",
    "# Calculate slope from DEM\n",
    "if isinstance(dem_data, np.ndarray):\n",
    "    # Synthetic slope calculation\n",
    "    from scipy.ndimage import sobel\n",
    "    dx = sobel(dem_data, axis=1)\n",
    "    dy = sobel(dem_data, axis=0)\n",
    "    slope_data = np.degrees(np.arctan(np.sqrt(dx**2 + dy**2)))\n",
    "else:\n",
    "    # Use DEM processor to calculate slope\n",
    "    slope_data = dem_processor.calculate_slope()\n",
    "\n",
    "# Create slope-based risk factor (landslide risk)\n",
    "# Steeper slopes have higher risk\n",
    "landslide_risk = SpatialRiskFactor(\n",
    "    name=\"Landslide Risk\",\n",
    "    description=\"Risk based on terrain slope (steeper slopes have higher risk)\",\n",
    "    risk_weight=0.3,\n",
    "    spatial_data=slope_data,\n",
    "    geo_transform=geo_transform,\n",
    "    transform_func=lambda slope: np.clip(slope / 45.0, 0, 1)  # Normalize to 0-1 (45 degrees is max risk)\n",
    ")\n",
    "\n",
    "# Visualize the risk factors\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "im1 = axes[0].imshow(flood_risk.risk_data, cmap='viridis_r', origin='upper')\n",
    "axes[0].set_title('Flood Risk')\n",
    "plt.colorbar(im1, ax=axes[0])\n",
    "\n",
    "im2 = axes[1].imshow(landslide_risk.risk_data, cmap='viridis_r', origin='upper')\n",
    "axes[1].set_title('Landslide Risk')\n",
    "plt.colorbar(im2, ax=axes[1])\n",
    "\n",
    "for ax in axes:\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Create Geospatial Risk Model\n",
    "\n",
    "Now we'll create a geospatial risk model that combines the risk factors we created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create geospatial risk model\n",
    "risk_model = GeospatialRiskModel(device_id=device_id)\n",
    "\n",
    "# Add risk factors\n",
    "risk_model.add_risk_factor(flood_risk)\n",
    "risk_model.add_risk_factor(landslide_risk)\n",
    "\n",
    "# Generate a combined risk map\n",
    "risk_map, risk_geo_transform = risk_model.get_risk_map(\n",
    "    min_x=0, min_y=0, max_x=10, max_y=10, resolution=0.02\n",
    ")\n",
    "\n",
    "# Visualize the combined risk map\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.imshow(risk_map, cmap='viridis_r', origin='upper')\n",
    "plt.colorbar(label='Combined Risk')\n",
    "plt.title('Combined Geospatial Risk Map')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Create Geospatial Portfolio\n",
    "\n",
    "Now we'll create a geospatial portfolio using our asset data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create geospatial portfolio\n",
    "portfolio = GeospatialPortfolio(device_id=device_id)\n",
    "\n",
    "# Add assets from DataFrame\n",
    "portfolio.add_assets_from_dataframe(\n",
    "    df=assets_df_with_returns,\n",
    "    id_col='id',\n",
    "    name_col='name',\n",
    "    value_col='value',\n",
    "    x_col='x',\n",
    "    y_col='y',\n",
    "    returns_col='returns',\n",
    "    metadata_cols=['sector'] if 'sector' in assets_df_with_returns.columns else None\n",
    ")\n",
    "\n",
    "# Visualize portfolio assets on the risk map\n",
    "visualizer = GeoFinancialVisualizer(figsize=(12, 10))\n",
    "fig = visualizer.plot_portfolio_on_risk_map(\n",
    "    risk_map=risk_map,\n",
    "    geo_transform=risk_geo_transform,\n",
    "    portfolio=portfolio,\n",
    "    title=\"Portfolio Assets on Risk Map\"\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Analyze Portfolio Risk\n",
    "\n",
    "Now we'll analyze the geospatial risk of our portfolio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assess risk for all assets\n",
    "risk_scores = portfolio.assess_risk(risk_model)\n",
    "\n",
    "# Print risk scores\n",
    "print(\"Geospatial Risk Scores:\")\n",
    "for asset_id, risk_score in sorted(risk_scores.items(), key=lambda x: x[1], reverse=True):\n",
    "    asset = next((a for a in portfolio.assets if a['id'] == asset_id), None)\n",
    "    if asset:\n",
    "        print(f\"{asset['name']} (${asset['value']:.2f}): {risk_score:.4f}\")\n",
    "\n",
    "# Visualize risk scores as a heatmap\n",
    "fig = visualizer.plot_portfolio_risk_heatmap(\n",
    "    portfolio=portfolio,\n",
    "    risk_scores=risk_scores,\n",
    "    title=\"Asset Risk Heatmap\"\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Financial Risk Analysis\n",
    "\n",
    "Now we'll analyze the financial risk of our portfolio using traditional financial risk metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate portfolio Value-at-Risk (VaR)\n",
    "try:\n",
    "    portfolio_var = portfolio.calculate_portfolio_var(confidence_level=0.95)\n",
    "    print(f\"Portfolio Value-at-Risk (95%): {portfolio_var:.4%}\")\n",
    "except ValueError as e:\n",
    "    print(f\"Error calculating VaR: {e}\")\n",
    "    print(\"Using synthetic VaR for demonstration purposes\")\n",
    "    portfolio_var = 0.0251  # 2.51% daily VaR\n",
    "    print(f\"Synthetic Portfolio Value-at-Risk (95%): {portfolio_var:.4%}\")\n",
    "\n",
    "# Check for correlation between asset returns and geospatial risk\n",
    "if all(len(asset['returns']) > 0 for asset in portfolio.assets):\n",
    "    # Calculate average returns for each asset\n",
    "    avg_returns = [np.mean(asset['returns']) for asset in portfolio.assets]\n",
    "    # Get risk scores in the same order\n",
    "    asset_risks = [risk_scores[asset['id']] for asset in portfolio.assets]\n",
    "    \n",
    "    # Calculate correlation\n",
    "    corr = np.corrcoef(avg_returns, asset_risks)[0, 1]\n",
    "    \n",
    "    print(f\"Correlation between returns and geospatial risk: {corr:.4f}\")\n",
    "    \n",
    "    # Visualize correlation\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.scatter(asset_risks, avg_returns, alpha=0.7)\n",
    "    plt.xlabel('Geospatial Risk Score')\n",
    "    plt.ylabel('Average Daily Return')\n",
    "    plt.title('Geospatial Risk vs. Returns Correlation')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add trend line\n",
    "    z = np.polyfit(asset_risks, avg_returns, 1)\n",
    "    p = np.poly1d(z)\n",
    "    plt.plot(np.array(asset_risks), p(np.array(asset_risks)), \"r--\", alpha=0.8)\n",
    "    \n",
    "    # Add annotation with correlation coefficient\n",
    "    plt.annotate(f\"Correlation: {corr:.4f}\", \n",
    "                xy=(0.05, 0.95), xycoords='axes fraction',\n",
    "                bbox=dict(boxstyle=\"round,pad=0.3\", fc=\"white\", ec=\"gray\", alpha=0.8))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Portfolio Optimization\n",
    "\n",
    "Now we'll optimize our portfolio to minimize exposure to geospatial risk while maintaining a target return."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get original weights\n",
    "total_value = sum(asset['value'] for asset in portfolio.assets)\n",
    "original_weights = {asset['id']: asset['value'] / total_value for asset in portfolio.assets}\n",
    "\n",
    "# Print original weights\n",
    "print(\"Original Portfolio Weights:\")\n",
    "for asset_id, weight in sorted(original_weights.items(), key=lambda x: x[1], reverse=True):\n",
    "    asset = next((a for a in portfolio.assets if a['id'] == asset_id), None)\n",
    "    if asset:\n",
    "        print(f\"{asset['name']}: {weight:.4f}\")\n",
    "\n",
    "# Set target return (slightly lower than current average return to allow optimization)\n",
    "try:\n",
    "    # Calculate current portfolio return\n",
    "    current_returns = np.array([np.mean(asset['returns']) for asset in portfolio.assets])\n",
    "    current_weights = np.array([original_weights[asset['id']] for asset in portfolio.assets])\n",
    "    current_portfolio_return = np.sum(current_returns * current_weights)\n",
    "    \n",
    "    # Set target return slightly lower\n",
    "    target_return = 0.9 * current_portfolio_return\n",
    "    \n",
    "    print(f\"Current portfolio return: {current_portfolio_return:.6f}\")\n",
    "    print(f\"Target return for optimization: {target_return:.6f}\")\n",
    "except (ValueError, KeyError) as e:\n",
    "    print(f\"Error calculating current return: {e}\")\n",
    "    print(\"Using synthetic target return for demonstration purposes\")\n",
    "    target_return = 0.0004  # 0.04% daily return target\n",
    "    \n",
    "# Optimize portfolio to minimize geospatial risk\n",
    "try:\n",
    "    optimized_weights = portfolio.optimize_for_geo_risk(\n",
    "        risk_model=risk_model,\n",
    "        target_return=target_return,\n",
    "        max_risk_score=0.5,\n",
    "        risk_aversion=2.0\n",
    "    )\n",
    "    \n",
    "    # Print optimized weights\n",
    "    print(\"\\nOptimized Portfolio Weights:\")\n",
    "    for asset_id, weight in sorted(optimized_weights.items(), key=lambda x: x[1], reverse=True):\n",
    "        asset = next((a for a in portfolio.assets if a['id'] == asset_id), None)\n",
    "        if asset:\n",
    "            print(f\"{asset['name']}: {weight:.4f}\")\n",
    "    \n",
    "    # Visualize original vs. optimized weights\n",
    "    fig = visualizer.plot_portfolio_optimization_results(\n",
    "        portfolio=portfolio,\n",
    "        original_weights=original_weights,\n",
    "        optimized_weights=optimized_weights,\n",
    "        risk_scores=risk_scores,\n",
    "        title=\"Portfolio Optimization Results\"\n",
    "    )\n",
    "    plt.show()\n",
    "except Exception as e:\n",
    "    print(f\"Error optimizing portfolio: {e}\")\n",
    "    print(\"Synthetic optimization will be used for demonstration purposes\")\n",
    "    \n",
    "    # Create synthetic optimized weights (reduce weights of high-risk assets)\n",
    "    optimized_weights = {}\n",
    "    for asset_id, orig_weight in original_weights.items():\n",
    "        risk = risk_scores.get(asset_id, 0.5)\n",
    "        # Reduce weight based on risk (higher risk = more reduction)\n",
    "        optimized_weights[asset_id] = orig_weight * (1.0 - 0.5 * risk)\n",
    "    \n",
    "    # Normalize weights to sum to 1.0\n",
    "    weight_sum = sum(optimized_weights.values())\n",
    "    optimized_weights = {k: v / weight_sum for k, v in optimized_weights.items()}\n",
    "    \n",
    "    # Print optimized weights\n",
    "    print(\"\\nSynthetic Optimized Portfolio Weights:\")\n",
    "    for asset_id, weight in sorted(optimized_weights.items(), key=lambda x: x[1], reverse=True):\n",
    "        asset = next((a for a in portfolio.assets if a['id'] == asset_id), None)\n",
    "        if asset:\n",
    "            print(f\"{asset['name']}: {weight:.4f}\")\n",
    "    \n",
    "    # Visualize original vs. optimized weights\n",
    "    fig = visualizer.plot_portfolio_optimization_results(\n",
    "        portfolio=portfolio,\n",
    "        original_weights=original_weights,\n",
    "        optimized_weights=optimized_weights,\n",
    "        risk_scores=risk_scores,\n",
    "        title=\"Synthetic Portfolio Optimization Results\"\n",
    "    )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Dashboard Visualization\n",
    "\n",
    "Finally, we'll create a comprehensive dashboard that visualizes all aspects of our geospatial financial risk analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive dashboard\n",
    "fig = visualizer.create_dashboard(\n",
    "    risk_model=risk_model,\n",
    "    portfolio=portfolio,\n",
    "    risk_map=risk_map,\n",
    "    geo_transform=risk_geo_transform,\n",
    "    optimized_weights=optimized_weights\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Performance Analysis\n",
    "\n",
    "Let's measure the performance of our GPU-accelerated geospatial financial risk analysis compared to CPU-only execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Define function to time execution\n",
    "def time_execution(func, *args, **kwargs):\n",
    "    start_time = time.time()\n",
    "    result = func(*args, **kwargs)\n",
    "    elapsed = time.time() - start_time\n",
    "    return result, elapsed\n",
    "\n",
    "# Test GPU execution (if available)\n",
    "if device_id >= 0:\n",
    "    print(\"Testing GPU execution performance...\")\n",
    "    # Create GPU-based model\n",
    "    gpu_risk_model = GeospatialRiskModel(device_id=device_id)\n",
    "    gpu_risk_model.add_risk_factor(flood_risk)\n",
    "    gpu_risk_model.add_risk_factor(landslide_risk)\n",
    "    \n",
    "    # Create GPU-based portfolio\n",
    "    gpu_portfolio = GeospatialPortfolio(device_id=device_id)\n",
    "    gpu_portfolio.add_assets_from_dataframe(\n",
    "        df=assets_df_with_returns,\n",
    "        id_col='id',\n",
    "        name_col='name',\n",
    "        value_col='value',\n",
    "        x_col='x',\n",
    "        y_col='y',\n",
    "        returns_col='returns'\n",
    "    )\n",
    "    \n",
    "    # Time risk map generation\n",
    "    _, gpu_risk_map_time = time_execution(\n",
    "        gpu_risk_model.get_risk_map,\n",
    "        min_x=0, min_y=0, max_x=10, max_y=10, resolution=0.01\n",
    "    )\n",
    "    \n",
    "    # Time risk assessment\n",
    "    _, gpu_risk_assessment_time = time_execution(\n",
    "        gpu_portfolio.assess_risk,\n",
    "        gpu_risk_model\n",
    "    )\n",
    "    \n",
    "    # Time portfolio optimization (if possible)\n",
    "    try:\n",
    "        _, gpu_optimization_time = time_execution(\n",
    "            gpu_portfolio.optimize_for_geo_risk,\n",
    "            risk_model=gpu_risk_model,\n",
    "            target_return=target_return,\n",
    "            max_risk_score=0.5,\n",
    "            risk_aversion=2.0\n",
    "        )\n",
    "    except Exception:\n",
    "        gpu_optimization_time = None\n",
    "\n",
    "# Test CPU execution\n",
    "print(\"Testing CPU execution performance...\")\n",
    "# Create CPU-based model\n",
    "cpu_risk_model = GeospatialRiskModel(device_id=-1)\n",
    "cpu_risk_model.add_risk_factor(flood_risk)\n",
    "cpu_risk_model.add_risk_factor(landslide_risk)\n",
    "\n",
    "# Create CPU-based portfolio\n",
    "cpu_portfolio = GeospatialPortfolio(device_id=-1)\n",
    "cpu_portfolio.add_assets_from_dataframe(\n",
    "    df=assets_df_with_returns,\n",
    "    id_col='id',\n",
    "    name_col='name',\n",
    "    value_col='value',\n",
    "    x_col='x',\n",
    "    y_col='y',\n",
    "    returns_col='returns'\n",
    ")\n",
    "\n",
    "# Time risk map generation\n",
    "_, cpu_risk_map_time = time_execution(\n",
    "    cpu_risk_model.get_risk_map,\n",
    "    min_x=0, min_y=0, max_x=10, max_y=10, resolution=0.01\n",
    ")\n",
    "\n",
    "# Time risk assessment\n",
    "_, cpu_risk_assessment_time = time_execution(\n",
    "    cpu_portfolio.assess_risk,\n",
    "    cpu_risk_model\n",
    ")\n",
    "\n",
    "# Time portfolio optimization (if possible)\n",
    "try:\n",
    "    _, cpu_optimization_time = time_execution(\n",
    "        cpu_portfolio.optimize_for_geo_risk,\n",
    "        risk_model=cpu_risk_model,\n",
    "        target_return=target_return,\n",
    "        max_risk_score=0.5,\n",
    "        risk_aversion=2.0\n",
    "    )\n",
    "except Exception:\n",
    "    cpu_optimization_time = None\n",
    "\n",
    "# Create performance comparison table\n",
    "print(\"\\nPerformance Comparison (CPU vs. GPU):\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"{'Operation':<25} {'CPU Time (s)':<15} {'GPU Time (s)':<15} {'Speedup':<10}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# Risk map generation\n",
    "if device_id >= 0:\n",
    "    speedup = cpu_risk_map_time / gpu_risk_map_time if gpu_risk_map_time > 0 else float('inf')\n",
    "    print(f\"{'Risk Map Generation':<25} {cpu_risk_map_time:<15.4f} {gpu_risk_map_time:<15.4f} {speedup:<10.2f}x\")\n",
    "else:\n",
    "    print(f\"{'Risk Map Generation':<25} {cpu_risk_map_time:<15.4f} {'N/A':<15} {'N/A':<10}\")\n",
    "\n",
    "# Risk assessment\n",
    "if device_id >= 0:\n",
    "    speedup = cpu_risk_assessment_time / gpu_risk_assessment_time if gpu_risk_assessment_time > 0 else float('inf')\n",
    "    print(f\"{'Risk Assessment':<25} {cpu_risk_assessment_time:<15.4f} {gpu_risk_assessment_time:<15.4f} {speedup:<10.2f}x\")\n",
    "else:\n",
    "    print(f\"{'Risk Assessment':<25} {cpu_risk_assessment_time:<15.4f} {'N/A':<15} {'N/A':<10}\")\n",
    "\n",
    "# Portfolio optimization\n",
    "if cpu_optimization_time is not None and gpu_optimization_time is not None and device_id >= 0:\n",
    "    speedup = cpu_optimization_time / gpu_optimization_time if gpu_optimization_time > 0 else float('inf')\n",
    "    print(f\"{'Portfolio Optimization':<25} {cpu_optimization_time:<15.4f} {gpu_optimization_time:<15.4f} {speedup:<10.2f}x\")\n",
    "elif cpu_optimization_time is not None:\n",
    "    print(f\"{'Portfolio Optimization':<25} {cpu_optimization_time:<15.4f} {'N/A':<15} {'N/A':<10}\")\n",
    "else:\n",
    "    print(f\"{'Portfolio Optimization':<25} {'N/A':<15} {'N/A':<15} {'N/A':<10}\")\n",
    "\n",
    "print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Conclusion\n",
    "\n",
    "In this notebook, we demonstrated the integration of the Financial Modeling and Geospatial Analysis workloads to create a comprehensive geospatial financial risk analysis tool. This integration allows for more sophisticated risk assessment and portfolio optimization by incorporating geospatial factors into financial decision-making.\n",
    "\n",
    "The key features demonstrated include:\n",
    "\n",
    "1. **Geospatial Risk Factors**: Created risk factors based on elevation (flood risk) and slope (landslide risk) data.\n",
    "2. **Integrated Risk Model**: Combined multiple spatial risk factors into a unified risk model.\n",
    "3. **Portfolio Risk Assessment**: Analyzed how geospatial risks affect financial assets based on their locations.\n",
    "4. **Risk-Aware Portfolio Optimization**: Adjusted portfolio weights to minimize exposure to geospatial risks while maintaining target returns.\n",
    "5. **GPU Acceleration**: Leveraged GPU computing to accelerate complex geospatial and financial calculations.\n",
    "6. **Visualization**: Created comprehensive visualizations to communicate geospatial financial risk insights.\n",
    "\n",
    "This approach demonstrates how the GPU adaptability pattern can be applied across multiple domains to create powerful, integrated analytical tools that leverage NVIDIA GPU hardware efficiently."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}